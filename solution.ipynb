{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Data Science Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 101)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# ## Data Description\n",
    "\n",
    "# Column | Description\n",
    "# :---|:---------\n",
    "# `title` |Title of the movie|\n",
    "# `country` | Countries in which movie was released|\n",
    "# `genres` | Movie Genres (Action ,Adventure, Comedy etc.)\n",
    "# `language` | Languages in which movie was released\n",
    "# `writer_count` | Number of writers of the movie\n",
    "# `title_adaption` | Is movie original screenplay or adapted.\n",
    "# `censor_rating` | Release rating given to the movie (R /PG-13/PG/NR/UR/G)\n",
    "# `release_date` | Date when movie was released\n",
    "# `runtime` | Movie runtime\n",
    "# `dvd_release_date` | Date of release of DVD for sale\n",
    "# `users_votes` | Number of users who voted for this movie to be included in Watch-It library\n",
    "# `comments` | Number of comments on movie trailer(as of now)\n",
    "# `likes` | Number of likes on movie trailer (as of now)\n",
    "# `overall_views` | Number of views on movie trailer (as of now)\n",
    "# `dislikes` | Number of dislikes on movie trailer (as of now)\n",
    "# `ratings_imdb` | Rating given to movie on IMDB.\n",
    "# `ratings_tomatoes` | Rating given to movie on Rotten tomatoes.\n",
    "# `ratings_metacritic` | Rating given to movie on Metacritic etc.\n",
    "# `special_award` | Number of awards nominations/winnings in BAFTA, Oscar or  Golden Globe.\n",
    "# `awards_win` | awards won by the movie\n",
    "# `awards_nomination` | Number of awards nominations\n",
    "# `revenue_category` | Revenue Category (High/Low)\n",
    "\n",
    "# ## Data Wrangling & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f612f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Dataset is already loaded below\n",
    "train_data = pd.read_excel(io=\"data.xlsx\", sheet_name='train')\n",
    "\n",
    "# extract label and transofrm to np.array\n",
    "y = train_data[[\"revenue_category\"]].copy()\n",
    "y_le = LabelEncoder()\n",
    "y['revenue_category'] = y_le.fit_transform(y['revenue_category'])\n",
    "y = y.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb746088",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Explore columns\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3b6bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde29d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def convert_to_float_imdb(x):\n",
    "    return float(x.split('/')[0]) / 10\n",
    "\n",
    "def convert_to_float_meta(x):\n",
    "    return float(x.split('/')[0]) / 100\n",
    "\n",
    "def convert_to_float_tomato(x):\n",
    "    return float(x.split('%')[0]) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616df980",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, test):\n",
    "    \n",
    "    # drop columns with probable no effect on the accuracy\n",
    "    data = data.drop(['title','title_adaption'], axis=1)\n",
    "    \n",
    "    data.censor_rating = data.censor_rating.astype(str)\n",
    "    data.writer_count = data.writer_count.astype('Int64')\n",
    "    data['writer_count'] = data['writer_count'].fillna(0)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    data['censor_encoded'] = le.fit_transform(data['censor_rating'])\n",
    "    \n",
    "    # hot encode genres and language country\n",
    "    encoded = pd.get_dummies(data['genres'].str.split(',\\s+').explode()).sum(level=0)\n",
    "    data = pd.concat([data, encoded], axis=1)\n",
    "\n",
    "    encoded = pd.get_dummies(data['language'].str.split(',\\s+').explode()).sum(level=0)\n",
    "    data = pd.concat([data, encoded], axis=1)\n",
    "    \n",
    "    encoded = pd.get_dummies(data['country'].str.split(',\\s+').explode()).sum(level=0)\n",
    "    data = pd.concat([data, encoded], axis=1)\n",
    "    \n",
    "    # extract day month year from release date and dvd rel date\n",
    "    data['release_date'] = data['release_date'].fillna('31-May-90')\n",
    "    data['release_date']= pd.to_datetime(data['release_date'], format='%d-%b-%y')\n",
    "    data['release_day']=data['release_date'].apply(lambda x:x.weekday())\n",
    "    data['release_month']=data['release_date'].apply(lambda x:x.month)\n",
    "    data['release_year']=data['release_date'].apply(lambda x:x.year)\n",
    "\n",
    "    data['dvd_release_date'] = data['dvd_release_date'].fillna('31-May-90')\n",
    "    data['dvd_release_date']= pd.to_datetime(data['dvd_release_date'], format='%d-%b-%y')\n",
    "    data['dvd_release_day']=data['dvd_release_date'].apply(lambda x:x.weekday())\n",
    "    data['dvd_release_month']=data['dvd_release_date'].apply(lambda x:x.month)\n",
    "    data['dvd_release_year']=data['dvd_release_date'].apply(lambda x:x.year)\n",
    "    \n",
    "    # remove strings and turn into numeral\n",
    "    data.runtime = data.runtime.str.replace(' min' , '')\n",
    "    data.runtime = data.runtime.astype(int)\n",
    "\n",
    "    data.users_votes = data.users_votes.str.replace(',' , '')\n",
    "    data.users_votes = data.users_votes.astype(int)\n",
    "    \n",
    "    # fill empty with 0\n",
    "    data.comments = data.comments.astype('Int64')\n",
    "    data['comments'] = data['comments'].fillna(0)\n",
    "\n",
    "    data.likes = data.likes.astype('Int64')\n",
    "    data['likes'] = data['likes'].fillna(0)\n",
    "\n",
    "    data.dislikes = data.dislikes.astype('Int64')\n",
    "    data['dislikes'] = data['dislikes'].fillna(0)\n",
    "\n",
    "    data.overall_views = data.overall_views.astype('Int64')\n",
    "    data['overall_views'] = data['overall_views'].fillna(0)\n",
    "    \n",
    "    # convert ratings to float\n",
    "    data['ratings_imdb'] = data['ratings_imdb'].apply(convert_to_float_imdb)\n",
    "    data['ratings_metacritic'] = data['ratings_metacritic'].apply(convert_to_float_meta)\n",
    "    data['ratings_tomatoes'] = data['ratings_tomatoes'].apply(convert_to_float_tomato)\n",
    "    \n",
    "    # remove label column if not in test mode\n",
    "    if test==False:\n",
    "        data = data.drop(['genres','language','censor_rating','release_date','dvd_release_date','country','revenue_category'], axis=1)\n",
    "\n",
    "    else:\n",
    "        data = data.drop(['genres','language','censor_rating','release_date','dvd_release_date','country'], axis=1)\n",
    "    \n",
    "    columns_to_scale = ['writer_count', 'runtime', 'users_votes', 'comments', 'likes',\n",
    "                        'overall_views', 'dislikes','special_award','awards_win','awards_nomination']\n",
    "\n",
    "    features = data[columns_to_scale]\n",
    "    scaler = StandardScaler().fit(features.values)\n",
    "    data[columns_to_scale] = scaler.transform(features.values)\n",
    "\n",
    "    return data, data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e589e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train_df, columns = prepare_data(train_data, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df\n",
    "\n",
    "\n",
    "# ## Visualization, Modeling, Machine Learning\n",
    "# \n",
    "# Can you build a model that can help them predict what titles would be suitable for licensing and identify how different features influence their decision? Please explain your findings effectively to technical and non-technical audiences using comments and visualizations, if appropriate.\n",
    "# - **Build an optimized model that effectively solves the business problem.**\n",
    "# - **The model would be evaluated on the basis of accuracy.**\n",
    "# - **Read the test.csv file and prepare features for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd94fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Loading Test data\n",
    "test_data=pd.read_excel(io=\"data.xlsx\", sheet_name='test')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52801676",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_df,columns_test = prepare_data(test_data, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5dbba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# some genres or languages might not be in the test set - \n",
    "# make sure that they have the same columsn and column order\n",
    "cols = test_df.columns.union(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3134580",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_df = test_df.reindex(columns=cols, fill_value=0)\n",
    "train_df = train_df.reindex(columns=cols, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590d9fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,:].values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ab9f1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e7592",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946bab7a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7cc03",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1feae6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 10, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0588ca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bff059",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b255d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af267b34",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 40, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893f316",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.iloc[:,:].values\n",
    "print(X_test.shape)\n",
    "\n",
    "# train with whole data\n",
    "classifier = RandomForestClassifier(n_estimators = 40, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X, y)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# \n",
    "# \n",
    "# **The management wants to know what are the most important features for your model.  Can you tell them?**\n",
    "# \n",
    "# > #### Task:\n",
    "# - **Visualize the top 20 features and their feature importance.**\n",
    "# \n",
    "\n",
    "# **Visualize the top 20 features and their feature importance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(classifier.feature_importances_, index=cols)\n",
    "   .nlargest(20)\n",
    "   .plot(kind='barh')) \n",
    "\n",
    "\n",
    "# **Visualize all features and their feature importance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifier.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), cols[indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "\n",
    "\n",
    "# > #### Task:\n",
    "# - **Submit the predictions on the test dataset using your optimized model** <br/>\n",
    "#     For each record in the test set (`test.csv`), you must predict the value of the `revenue_category` variable. You should submit a CSV file with a header row and one row per test entry. The file (submissions.csv) should have exactly 2 columns:\n",
    "# \n",
    "# The file (`submissions.csv`) should have exactly 2 columns:\n",
    "#    - **title**\n",
    "#    - **revenue_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816654d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Loading Test data\n",
    "test_data=pd.read_excel(dtype=str, io=\"data.xlsx\", sheet_name='test')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d573f01",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "submission_df = test_data['title'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d46a6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "revemie_df = pd.DataFrame(y_le.inverse_transform(y_pred),columns=['revenue_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7844dff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "submission_df = pd.concat([submission_df,revemie_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffaeca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bcb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission\n",
    "submission_df.to_csv('submissions.csv',index=False)\n",
    "# ---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
